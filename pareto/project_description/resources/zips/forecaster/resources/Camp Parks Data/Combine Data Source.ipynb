{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileList(srch_dir):\n",
    "    '''this function finds all files in a given directory\n",
    "    '''\n",
    "    \n",
    "    file_list = []\n",
    "    for root, directories, filenames in os.walk(srch_dir):\n",
    "        for filename in filenames: \n",
    "            if filename.lower()[-4:]=='.csv':\n",
    "                file_list.append(os.path.join(root,filename) )\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def generateUnixTime(row):\n",
    "    '''\n",
    "        function to convert string timestamp and daylist savings flag to unix time\n",
    "        \n",
    "        attempts to process the two datetime string formats found in the current dataset\n",
    "        but will fail if any other datetime string format is present\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        dt = datetime.strptime(row['Time'], \"%m/%d/%Y %H:%M\")\n",
    "    except:\n",
    "        try:\n",
    "           dt = datetime.strptime(row['Time'], \"%Y-%m-%d %H:%M\")\n",
    "        except:\n",
    "            print('datetime conversion failed')\n",
    "            print(row['Time'])\n",
    "            dt = 0\n",
    "    \n",
    "    dt = (dt - datetime(1970,1,1)).total_seconds()\n",
    "    \n",
    "    # add time diff depending on DST flag\n",
    "    if row['Daylight Savings Flag'] == 'Y':\n",
    "        dt += 7*60*60\n",
    "    elif row['Daylight Savings Flag'] == 'N':\n",
    "        dt += 8*60*60\n",
    "    else:\n",
    "        print('missing DST flag')\n",
    "    \n",
    "    return dt\n",
    "\n",
    "\n",
    "def extractLoadForYear(inFolder):\n",
    "    '''\n",
    "        function finds all csv files in given folder, reads them as panda dfs and combines them\n",
    "        converts timestamp to unix time, then drops unnecessary columns\n",
    "        \n",
    "        preseves unix time and original timestamp and DST flag\n",
    "        \n",
    "        aggregates all submeters into single total load amount\n",
    "        \n",
    "    '''\n",
    "    \n",
    "\n",
    "    # look in directory for load files\n",
    "    fileList = getFileList(inFolder)\n",
    "\n",
    "    # intialize dataframe var\n",
    "    results = None\n",
    "\n",
    "    # loop through found files\n",
    "    for ff in fileList:\n",
    "        \n",
    "        print('reading: %s' %ff)\n",
    "        \n",
    "        # read files in list to dataframe\n",
    "        df = pd.read_csv(ff)\n",
    "        \n",
    "        \n",
    "        # drop and process columns\n",
    "\n",
    "        # add to cumulative dataframe\n",
    "        if results is None:\n",
    "            print('initializing df with %s' %ff)\n",
    "            results = df\n",
    "        else:\n",
    "            print('ading data from %s' %ff)\n",
    "            results = pd.concat([results, df])\n",
    "            \n",
    "    return results\n",
    "\n",
    "\n",
    "def processLoadData(inFolder):\n",
    "\n",
    "    # extract and combine load data from files in inFolder\n",
    "    results = extractLoadForYear(inFolder)\n",
    "\n",
    "    # generate unix timestamp\n",
    "    # this operation seems pretty inefficient, but not sure of a better way\n",
    "    # since unix time requires multiple fields to calaculate\n",
    "    results['unixTime'] = results.apply(generateUnixTime, axis=1)\n",
    "    \n",
    "    # copy to results raw, to extract datetime\n",
    "    resultsRaw = results.copy(deep=True)\n",
    "    resultsRaw = resultsRaw[['unixTime', 'Time', 'Daylight Savings Flag']]\n",
    "    resultsRaw.columns = ['timestamp', 'datetime', 'dst']\n",
    "    \n",
    "    # drop rows and sum by timestamp\n",
    "    results = results[['unixTime', 'Usage Value']]\n",
    "    results = results.groupby(['unixTime'], as_index=False)['Usage Value'].sum()\n",
    "    \n",
    "    # convert timestep energy to power\n",
    "    results.columns = ['timestamp', 'load']\n",
    "    results.load = results.load * 4\n",
    "    \n",
    "    # add timestamp back to results df\n",
    "    rRight = results.set_index('timestamp')\n",
    "\n",
    "    rLeft = resultsRaw.drop_duplicates(subset=['timestamp'])\n",
    "    rLeft = rLeft.set_index('timestamp')\n",
    "\n",
    "    r2 = rRight.join(rLeft, how='left')\n",
    " \n",
    "    return r2\n",
    "\n",
    "def processLoadDataMeter(inFolder):\n",
    "\n",
    "    # extract and combine load data from files in inFolder\n",
    "    results = extractLoadForYear(inFolder)\n",
    "\n",
    "    # generate unix timestamp\n",
    "    # this operation seems pretty inefficient, but not sure of a better way\n",
    "    # since unix time requires multiple fields to calaculate\n",
    "    results['unixTime'] = results.apply(generateUnixTime, axis=1)\n",
    "    \n",
    "    # select and rename relevant columns\n",
    "    results = results[['unixTime', 'Time', 'Daylight Savings Flag', 'Meter Badge Number', 'Usage Value']]\n",
    "    results.columns = ['timestamp', 'datetime', 'dst', 'meter', 'load']\n",
    "    # convert timestep energy to power\n",
    "    results.load = results.load * 4\n",
    "    \n",
    "    # copy to results raw, to extract and reapply datetime/dst flag\n",
    "    resultsRaw = results.copy(deep=True)\n",
    "    resultsRaw = resultsRaw[['timestamp', 'datetime', 'dst']]\n",
    "    \n",
    "    # pivot results to make meter loads columns\n",
    "    results = results[results.load!=0]\n",
    "    results.reset_index(inplace=True)\n",
    "    results = results[['timestamp', 'meter', 'load']]\n",
    "    results = results.pivot(index='timestamp', columns='meter')\n",
    "\n",
    "    results.columns = results.columns.droplevel(0) #remove load multiIndex\n",
    "    results.columns.name = None               #remove categories\n",
    "    results = results.reset_index()                #index to columns\n",
    "\n",
    "\n",
    "    \n",
    "    # add timestamp back to results df\n",
    "    rRight = results.set_index('timestamp')\n",
    "\n",
    "    rLeft = resultsRaw.drop_duplicates(subset=['timestamp'])\n",
    "    rLeft = rLeft.set_index('timestamp')\n",
    "\n",
    "    r2 = rRight.join(rLeft, how='left')\n",
    " \n",
    "    return r2\n",
    "\n",
    "\n",
    "def combineWeather(leftData, rightData):\n",
    "    '''\n",
    "        function combines load data and weather data by matching closest unix timestamp\n",
    "        returns data for time index of leftData\n",
    "    '''\n",
    "    \n",
    "    # sort both by index\n",
    "    leftData = leftData.sort_index()\n",
    "    rightData = rightData.sort_index()\n",
    "    \n",
    "    # convert both indices to int\n",
    "    leftData.index = leftData.index.astype(int)\n",
    "    rightData.index = rightData.index.astype(int)\n",
    "    \n",
    "    combinedData = pd.merge_asof(leftData, rightData, on=\"timestamp\")\n",
    "    \n",
    "    return combinedData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract weather data from files\n",
    "w19 = pd.read_csv('/Users/nxd/Downloads/Parks Data/weather data/Camp Parks 2019 weather data.csv')\n",
    "w20 = pd.read_csv('/Users/nxd/Downloads/Parks Data/weather data/Camp Parks 2020 weather data.csv')\n",
    "\n",
    "# set timestamp as index\n",
    "w19 = w19.set_index('timestamp')\n",
    "w20 = w20.set_index('timestamp')\n",
    "\n",
    "# define directories for 2019 and 2020 data\n",
    "dir2019 = '/Users/nxd/Downloads/Parks Data/load data/2019'\n",
    "dir2020 = '/Users/nxd/Downloads/Parks Data/load data/2020'\n",
    "\n",
    "# process load data for 2019\n",
    "# r19 = processLoadData(dir2019)\n",
    "\n",
    "# proces load data for 2020\n",
    "# r20 = processLoadData(dir2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create weather-load tables for 2019 and 2020 for 15min and 1hr timesteps\n",
    "# # then write to file\n",
    "# c19 = combineWeather(r19, w19)\n",
    "# print(c19.shape)\n",
    "# c19.to_csv('/Users/nxd/Downloads/Parks Data/training data/Parks_2019_training_data_15min.csv')\n",
    "\n",
    "# c19b = combineWeather(w19, r19)\n",
    "# print(c19b.shape)\n",
    "# c19b.to_csv('/Users/nxd/Downloads/Parks Data/training data/Parks_2019_training_data_1hr.csv')\n",
    "\n",
    "# c20 = combineWeather(r20, w20)\n",
    "# print(c20.shape)\n",
    "# c20.to_csv('/Users/nxd/Downloads/Parks Data/training data/Parks_2020_training_data_15min.csv')\n",
    "\n",
    "# c20b = combineWeather(w20, r20)\n",
    "# print(c20b.shape)\n",
    "# c20b.to_csv('/Users/nxd/Downloads/Parks Data/training data/Parks_2020_training_data_1hr.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190901-20190930.csv\n",
      "initializing df with /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190901-20190930.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191101-20191130.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191101-20191130.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191201-20191231.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191201-20191231.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190201-20190228.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190201-20190228.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191001-20191031.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191001-20191031.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190801-20190831.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190801-20190831.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190501-20190531.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190501-20190531.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190601-20190630.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190601-20190630.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190301-20190331.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190301-20190331.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190401-20190430.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190401-20190430.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190101-20190131.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190101-20190131.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190701-20190731.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190701-20190731.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200701-20200731.csv\n",
      "initializing df with /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200701-20200731.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200401-20200430.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200401-20200430.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200101-20200131.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200101-20200131.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200601-20200630.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200601-20200630.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200301-20200331.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200301-20200331.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200501-20200531.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200501-20200531.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201001-20201031.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201001-20201031.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200801-20200831.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200801-20200831.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200901-20200930.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200901-20200930.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201201-20201231.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201201-20201231.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200201-20200229.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200201-20200229.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201101-20201130.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201101-20201130.csv\n",
      "(35136, 35)\n",
      "(8740, 35)\n",
      "(35136, 35)\n",
      "(8809, 35)\n"
     ]
    }
   ],
   "source": [
    "# code to generate meter-specific load training data\n",
    "m19 = processLoadDataMeter(dir2019)\n",
    "m20 = m19 = processLoadDataMeter(dir2020)\n",
    "\n",
    "# create weather-load tables for 2019 and 2020 for 15min and 1hr timesteps\n",
    "# then write to file\n",
    "c19 = combineWeather(m19, w19)\n",
    "print(c19.shape)\n",
    "c19.to_csv('/Users/nxd/Downloads/Parks Data/training data/Parks_2019_training_data_METER_15min.csv')\n",
    "\n",
    "c19b = combineWeather(w19, m19)\n",
    "print(c19b.shape)\n",
    "c19b.to_csv('/Users/nxd/Downloads/Parks Data/training data/Parks_2019_training_data_METER_1hr.csv')\n",
    "\n",
    "c20 = combineWeather(m20, w20)\n",
    "print(c20.shape)\n",
    "c20.to_csv('/Users/nxd/Downloads/Parks Data/training data/Parks_2020_training_data_METER_15min.csv')\n",
    "\n",
    "c20b = combineWeather(w20, m20)\n",
    "print(c20b.shape)\n",
    "c20b.to_csv('/Users/nxd/Downloads/Parks Data/training data/Parks_2020_training_data_METER_1hr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190901-20190930.csv\n",
      "initializing df with /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190901-20190930.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191101-20191130.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191101-20191130.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191201-20191231.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191201-20191231.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190201-20190228.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190201-20190228.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191001-20191031.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191001-20191031.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190801-20190831.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190801-20190831.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190501-20190531.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190501-20190531.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190601-20190630.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190601-20190630.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190301-20190331.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190301-20190331.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190401-20190430.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190401-20190430.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190101-20190131.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190101-20190131.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190701-20190731.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190701-20190731.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200701-20200731.csv\n",
      "initializing df with /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200701-20200731.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200401-20200430.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200401-20200430.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200101-20200131.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200101-20200131.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200601-20200630.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200601-20200630.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200301-20200331.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200301-20200331.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200501-20200531.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200501-20200531.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201001-20201031.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201001-20201031.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200801-20200831.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200801-20200831.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200901-20200930.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200901-20200930.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201201-20201231.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201201-20201231.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200201-20200229.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20200201-20200229.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201101-20201130.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2020/Historical_20201101-20201130.csv\n"
     ]
    }
   ],
   "source": [
    "# extract raw data to explore meter-level completeness\n",
    "rawData2019 = extractLoadForYear(dir2019)\n",
    "rawData2020 = extractLoadForYear(dir2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meter Badge Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004578059</th>\n",
       "      <td>70080</td>\n",
       "      <td>5.408226e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006706934</th>\n",
       "      <td>35040</td>\n",
       "      <td>1.752400e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006715799</th>\n",
       "      <td>35040</td>\n",
       "      <td>4.886148e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006716429</th>\n",
       "      <td>35040</td>\n",
       "      <td>1.870230e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006727093</th>\n",
       "      <td>35040</td>\n",
       "      <td>4.746609e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006727361</th>\n",
       "      <td>35040</td>\n",
       "      <td>5.866292e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008913626</th>\n",
       "      <td>35040</td>\n",
       "      <td>4.938008e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009074083</th>\n",
       "      <td>35040</td>\n",
       "      <td>2.518137e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009511425</th>\n",
       "      <td>35040</td>\n",
       "      <td>4.046645e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009540871</th>\n",
       "      <td>35040</td>\n",
       "      <td>8.963778e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009984043</th>\n",
       "      <td>35040</td>\n",
       "      <td>3.993185e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009984060</th>\n",
       "      <td>35040</td>\n",
       "      <td>1.430763e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010054507</th>\n",
       "      <td>35040</td>\n",
       "      <td>9.305148e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010086328</th>\n",
       "      <td>35040</td>\n",
       "      <td>8.913068e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010249061</th>\n",
       "      <td>35040</td>\n",
       "      <td>5.486829e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010282897</th>\n",
       "      <td>26053</td>\n",
       "      <td>1.077584e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010397607</th>\n",
       "      <td>11489</td>\n",
       "      <td>7.239740e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010409824</th>\n",
       "      <td>35040</td>\n",
       "      <td>2.227410e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           sum\n",
       "Meter Badge Number                     \n",
       "1004578059          70080  5.408226e+06\n",
       "1006706934          35040  1.752400e+05\n",
       "1006715799          35040  4.886148e+04\n",
       "1006716429          35040  1.870230e+05\n",
       "1006727093          35040  4.746609e+05\n",
       "1006727361          35040  5.866292e+04\n",
       "1008913626          35040  4.938008e+03\n",
       "1009074083          35040  2.518137e+03\n",
       "1009511425          35040  4.046645e+05\n",
       "1009540871          35040  8.963778e+04\n",
       "1009984043          35040  3.993185e+04\n",
       "1009984060          35040  1.430763e+05\n",
       "1010054507          35040  9.305148e+04\n",
       "1010086328          35040  8.913068e+05\n",
       "1010249061          35040  5.486829e+05\n",
       "1010282897          26053  1.077584e+05\n",
       "1010397607          11489  7.239740e+01\n",
       "1010409824          35040  2.227410e+05"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData2019.groupby('Meter Badge Number')['Usage Value'].agg(['count', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meter Badge Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004578059</th>\n",
       "      <td>69888</td>\n",
       "      <td>4.910166e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006706934</th>\n",
       "      <td>35136</td>\n",
       "      <td>2.156694e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006715799</th>\n",
       "      <td>35136</td>\n",
       "      <td>5.066628e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006716429</th>\n",
       "      <td>35136</td>\n",
       "      <td>1.917336e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006727093</th>\n",
       "      <td>35136</td>\n",
       "      <td>4.824462e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006727361</th>\n",
       "      <td>35136</td>\n",
       "      <td>4.504716e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008913626</th>\n",
       "      <td>35136</td>\n",
       "      <td>6.848189e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009074083</th>\n",
       "      <td>35136</td>\n",
       "      <td>1.527174e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009511425</th>\n",
       "      <td>35136</td>\n",
       "      <td>4.005050e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009540871</th>\n",
       "      <td>35136</td>\n",
       "      <td>8.500578e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009984043</th>\n",
       "      <td>35136</td>\n",
       "      <td>4.708072e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009984060</th>\n",
       "      <td>35136</td>\n",
       "      <td>1.397323e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010054507</th>\n",
       "      <td>35136</td>\n",
       "      <td>9.730472e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010086328</th>\n",
       "      <td>35136</td>\n",
       "      <td>8.931603e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010249061</th>\n",
       "      <td>35136</td>\n",
       "      <td>5.916657e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010282897</th>\n",
       "      <td>35136</td>\n",
       "      <td>1.707029e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010397607</th>\n",
       "      <td>35136</td>\n",
       "      <td>1.431890e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010409824</th>\n",
       "      <td>35136</td>\n",
       "      <td>2.305630e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010410390</th>\n",
       "      <td>11716</td>\n",
       "      <td>1.193964e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           sum\n",
       "Meter Badge Number                     \n",
       "1004578059          69888  4.910166e+06\n",
       "1006706934          35136  2.156694e+05\n",
       "1006715799          35136  5.066628e+04\n",
       "1006716429          35136  1.917336e+05\n",
       "1006727093          35136  4.824462e+05\n",
       "1006727361          35136  4.504716e+04\n",
       "1008913626          35136  6.848189e+03\n",
       "1009074083          35136  1.527174e+03\n",
       "1009511425          35136  4.005050e+05\n",
       "1009540871          35136  8.500578e+04\n",
       "1009984043          35136  4.708072e+04\n",
       "1009984060          35136  1.397323e+05\n",
       "1010054507          35136  9.730472e+04\n",
       "1010086328          35136  8.931603e+05\n",
       "1010249061          35136  5.916657e+05\n",
       "1010282897          35136  1.707029e+05\n",
       "1010397607          35136  1.431890e+03\n",
       "1010409824          35136  2.305630e+05\n",
       "1010410390          11716  1.193964e+04"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData2020.groupby('Meter Badge Number')['Usage Value'].agg(['count', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190901-20190930.csv\n",
      "initializing df with /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190901-20190930.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191101-20191130.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191101-20191130.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191201-20191231.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191201-20191231.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190201-20190228.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190201-20190228.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191001-20191031.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20191001-20191031.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190801-20190831.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190801-20190831.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190501-20190531.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190501-20190531.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190601-20190630.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190601-20190630.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190301-20190331.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190301-20190331.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190401-20190430.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190401-20190430.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190101-20190131.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190101-20190131.csv\n",
      "reading: /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190701-20190731.csv\n",
      "ading data from /Users/nxd/Downloads/Parks Data/load data/2019/Parks_Historical_20190701-20190731.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1004578059</th>\n",
       "      <th>1006706934</th>\n",
       "      <th>1006715799</th>\n",
       "      <th>1006716429</th>\n",
       "      <th>1006727093</th>\n",
       "      <th>1006727361</th>\n",
       "      <th>1008913626</th>\n",
       "      <th>1009074083</th>\n",
       "      <th>1009511425</th>\n",
       "      <th>1009540871</th>\n",
       "      <th>1009984043</th>\n",
       "      <th>1009984060</th>\n",
       "      <th>1010054507</th>\n",
       "      <th>1010086328</th>\n",
       "      <th>1010249061</th>\n",
       "      <th>1010282897</th>\n",
       "      <th>1010397607</th>\n",
       "      <th>1010409824</th>\n",
       "      <th>datetime</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.546330e+09</th>\n",
       "      <td>558.0</td>\n",
       "      <td>18.56</td>\n",
       "      <td>5.44</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.28</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.2376</td>\n",
       "      <td>26.88</td>\n",
       "      <td>8.16</td>\n",
       "      <td>3.244</td>\n",
       "      <td>22.348</td>\n",
       "      <td>8.96</td>\n",
       "      <td>76.48</td>\n",
       "      <td>22.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.96</td>\n",
       "      <td>1/1/2019 0:15</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.546331e+09</th>\n",
       "      <td>552.6</td>\n",
       "      <td>18.56</td>\n",
       "      <td>4.80</td>\n",
       "      <td>33.28</td>\n",
       "      <td>32.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>22.40</td>\n",
       "      <td>8.16</td>\n",
       "      <td>3.988</td>\n",
       "      <td>21.956</td>\n",
       "      <td>9.92</td>\n",
       "      <td>76.48</td>\n",
       "      <td>31.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.92</td>\n",
       "      <td>1/1/2019 0:30</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.546332e+09</th>\n",
       "      <td>549.6</td>\n",
       "      <td>18.24</td>\n",
       "      <td>4.80</td>\n",
       "      <td>33.28</td>\n",
       "      <td>31.36</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>24.32</td>\n",
       "      <td>9.12</td>\n",
       "      <td>3.124</td>\n",
       "      <td>22.076</td>\n",
       "      <td>10.24</td>\n",
       "      <td>72.32</td>\n",
       "      <td>27.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.80</td>\n",
       "      <td>1/1/2019 0:45</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.546333e+09</th>\n",
       "      <td>562.2</td>\n",
       "      <td>18.56</td>\n",
       "      <td>4.80</td>\n",
       "      <td>33.28</td>\n",
       "      <td>32.64</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>23.68</td>\n",
       "      <td>8.64</td>\n",
       "      <td>3.292</td>\n",
       "      <td>23.784</td>\n",
       "      <td>10.24</td>\n",
       "      <td>71.68</td>\n",
       "      <td>25.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.96</td>\n",
       "      <td>1/1/2019 1:00</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.546334e+09</th>\n",
       "      <td>549.6</td>\n",
       "      <td>18.24</td>\n",
       "      <td>5.12</td>\n",
       "      <td>33.28</td>\n",
       "      <td>35.20</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.7524</td>\n",
       "      <td>23.68</td>\n",
       "      <td>8.64</td>\n",
       "      <td>3.964</td>\n",
       "      <td>24.944</td>\n",
       "      <td>9.28</td>\n",
       "      <td>72.64</td>\n",
       "      <td>32.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.64</td>\n",
       "      <td>1/1/2019 1:15</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1004578059  1006706934  1006715799  1006716429  1006727093  \\\n",
       "timestamp                                                                  \n",
       "1.546330e+09       558.0       18.56        5.44       33.60       33.28   \n",
       "1.546331e+09       552.6       18.56        4.80       33.28       32.64   \n",
       "1.546332e+09       549.6       18.24        4.80       33.28       31.36   \n",
       "1.546333e+09       562.2       18.56        4.80       33.28       32.64   \n",
       "1.546334e+09       549.6       18.24        5.12       33.28       35.20   \n",
       "\n",
       "              1006727361  1008913626  1009074083  1009511425  1009540871  \\\n",
       "timestamp                                                                  \n",
       "1.546330e+09        0.96       0.796      0.2376       26.88        8.16   \n",
       "1.546331e+09        0.64       0.792      0.8652       22.40        8.16   \n",
       "1.546332e+09        1.28       0.800      0.9020       24.32        9.12   \n",
       "1.546333e+09        1.28       0.796      0.3804       23.68        8.64   \n",
       "1.546334e+09        0.96       0.792      0.7524       23.68        8.64   \n",
       "\n",
       "              1009984043  1009984060  1010054507  1010086328  1010249061  \\\n",
       "timestamp                                                                  \n",
       "1.546330e+09       3.244      22.348        8.96       76.48        22.8   \n",
       "1.546331e+09       3.988      21.956        9.92       76.48        31.2   \n",
       "1.546332e+09       3.124      22.076       10.24       72.32        27.6   \n",
       "1.546333e+09       3.292      23.784       10.24       71.68        25.2   \n",
       "1.546334e+09       3.964      24.944        9.28       72.64        32.4   \n",
       "\n",
       "              1010282897  1010397607  1010409824       datetime dst  \n",
       "timestamp                                                            \n",
       "1.546330e+09         NaN         NaN       24.96  1/1/2019 0:15   N  \n",
       "1.546331e+09         NaN         NaN       33.92  1/1/2019 0:30   N  \n",
       "1.546332e+09         NaN         NaN       28.80  1/1/2019 0:45   N  \n",
       "1.546333e+09         NaN         NaN       24.96  1/1/2019 1:00   N  \n",
       "1.546334e+09         NaN         NaN       32.64  1/1/2019 1:15   N  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = processLoadDataMeter(dir2019)\n",
    "# x2 = x.copy(deep=True)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646854, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35040, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>1004578059</th>\n",
       "      <th>1006706934</th>\n",
       "      <th>1006715799</th>\n",
       "      <th>1006716429</th>\n",
       "      <th>1006727093</th>\n",
       "      <th>1006727361</th>\n",
       "      <th>1008913626</th>\n",
       "      <th>1009074083</th>\n",
       "      <th>1009511425</th>\n",
       "      <th>1009540871</th>\n",
       "      <th>1009984043</th>\n",
       "      <th>1009984060</th>\n",
       "      <th>1010054507</th>\n",
       "      <th>1010086328</th>\n",
       "      <th>1010249061</th>\n",
       "      <th>1010282897</th>\n",
       "      <th>1010397607</th>\n",
       "      <th>1010409824</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.546330e+09</td>\n",
       "      <td>558.0</td>\n",
       "      <td>18.56</td>\n",
       "      <td>5.44</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.28</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.2376</td>\n",
       "      <td>26.88</td>\n",
       "      <td>8.16</td>\n",
       "      <td>3.244</td>\n",
       "      <td>22.348</td>\n",
       "      <td>8.96</td>\n",
       "      <td>76.48</td>\n",
       "      <td>22.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.546331e+09</td>\n",
       "      <td>552.6</td>\n",
       "      <td>18.56</td>\n",
       "      <td>4.80</td>\n",
       "      <td>33.28</td>\n",
       "      <td>32.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>22.40</td>\n",
       "      <td>8.16</td>\n",
       "      <td>3.988</td>\n",
       "      <td>21.956</td>\n",
       "      <td>9.92</td>\n",
       "      <td>76.48</td>\n",
       "      <td>31.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.546332e+09</td>\n",
       "      <td>549.6</td>\n",
       "      <td>18.24</td>\n",
       "      <td>4.80</td>\n",
       "      <td>33.28</td>\n",
       "      <td>31.36</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>24.32</td>\n",
       "      <td>9.12</td>\n",
       "      <td>3.124</td>\n",
       "      <td>22.076</td>\n",
       "      <td>10.24</td>\n",
       "      <td>72.32</td>\n",
       "      <td>27.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.546333e+09</td>\n",
       "      <td>562.2</td>\n",
       "      <td>18.56</td>\n",
       "      <td>4.80</td>\n",
       "      <td>33.28</td>\n",
       "      <td>32.64</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>23.68</td>\n",
       "      <td>8.64</td>\n",
       "      <td>3.292</td>\n",
       "      <td>23.784</td>\n",
       "      <td>10.24</td>\n",
       "      <td>71.68</td>\n",
       "      <td>25.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.546334e+09</td>\n",
       "      <td>549.6</td>\n",
       "      <td>18.24</td>\n",
       "      <td>5.12</td>\n",
       "      <td>33.28</td>\n",
       "      <td>35.20</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.7524</td>\n",
       "      <td>23.68</td>\n",
       "      <td>8.64</td>\n",
       "      <td>3.964</td>\n",
       "      <td>24.944</td>\n",
       "      <td>9.28</td>\n",
       "      <td>72.64</td>\n",
       "      <td>32.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  1004578059  1006706934  1006715799  1006716429  1006727093  \\\n",
       "0  1.546330e+09       558.0       18.56        5.44       33.60       33.28   \n",
       "1  1.546331e+09       552.6       18.56        4.80       33.28       32.64   \n",
       "2  1.546332e+09       549.6       18.24        4.80       33.28       31.36   \n",
       "3  1.546333e+09       562.2       18.56        4.80       33.28       32.64   \n",
       "4  1.546334e+09       549.6       18.24        5.12       33.28       35.20   \n",
       "\n",
       "   1006727361  1008913626  1009074083  1009511425  1009540871  1009984043  \\\n",
       "0        0.96       0.796      0.2376       26.88        8.16       3.244   \n",
       "1        0.64       0.792      0.8652       22.40        8.16       3.988   \n",
       "2        1.28       0.800      0.9020       24.32        9.12       3.124   \n",
       "3        1.28       0.796      0.3804       23.68        8.64       3.292   \n",
       "4        0.96       0.792      0.7524       23.68        8.64       3.964   \n",
       "\n",
       "   1009984060  1010054507  1010086328  1010249061  1010282897  1010397607  \\\n",
       "0      22.348        8.96       76.48        22.8         NaN         NaN   \n",
       "1      21.956        9.92       76.48        31.2         NaN         NaN   \n",
       "2      22.076       10.24       72.32        27.6         NaN         NaN   \n",
       "3      23.784       10.24       71.68        25.2         NaN         NaN   \n",
       "4      24.944        9.28       72.64        32.4         NaN         NaN   \n",
       "\n",
       "   1010409824  \n",
       "0       24.96  \n",
       "1       33.92  \n",
       "2       28.80  \n",
       "3       24.96  \n",
       "4       32.64  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x.copy(deep=True)\n",
    "x2 = x2[x2.load!=0]\n",
    "x2.reset_index(inplace=True)\n",
    "x2 = x2[['timestamp', 'meter', 'load']]\n",
    "x2 = x2.pivot(index='timestamp', columns='meter')\n",
    "\n",
    "x2.columns = x2.columns.droplevel(0) #remove load multiIndex\n",
    "x2.columns.name = None               #remove categories\n",
    "x2 = x2.reset_index()                #index to columns\n",
    "\n",
    "# print(x.shape)\n",
    "print(x2.shape)\n",
    "\n",
    "x2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>1004578059</th>\n",
       "      <th>1006706934</th>\n",
       "      <th>1006715799</th>\n",
       "      <th>1006716429</th>\n",
       "      <th>1006727093</th>\n",
       "      <th>1006727361</th>\n",
       "      <th>1008913626</th>\n",
       "      <th>1009074083</th>\n",
       "      <th>1009511425</th>\n",
       "      <th>1009540871</th>\n",
       "      <th>1009984043</th>\n",
       "      <th>1009984060</th>\n",
       "      <th>1010054507</th>\n",
       "      <th>1010086328</th>\n",
       "      <th>1010249061</th>\n",
       "      <th>1010282897</th>\n",
       "      <th>1010397607</th>\n",
       "      <th>1010409824</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.546330e+09</td>\n",
       "      <td>558.0</td>\n",
       "      <td>18.56</td>\n",
       "      <td>5.44</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.28</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.2376</td>\n",
       "      <td>26.88</td>\n",
       "      <td>8.16</td>\n",
       "      <td>3.244</td>\n",
       "      <td>22.348</td>\n",
       "      <td>8.96</td>\n",
       "      <td>76.48</td>\n",
       "      <td>22.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.546331e+09</td>\n",
       "      <td>552.6</td>\n",
       "      <td>18.56</td>\n",
       "      <td>4.80</td>\n",
       "      <td>33.28</td>\n",
       "      <td>32.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>22.40</td>\n",
       "      <td>8.16</td>\n",
       "      <td>3.988</td>\n",
       "      <td>21.956</td>\n",
       "      <td>9.92</td>\n",
       "      <td>76.48</td>\n",
       "      <td>31.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.546332e+09</td>\n",
       "      <td>549.6</td>\n",
       "      <td>18.24</td>\n",
       "      <td>4.80</td>\n",
       "      <td>33.28</td>\n",
       "      <td>31.36</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>24.32</td>\n",
       "      <td>9.12</td>\n",
       "      <td>3.124</td>\n",
       "      <td>22.076</td>\n",
       "      <td>10.24</td>\n",
       "      <td>72.32</td>\n",
       "      <td>27.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.546333e+09</td>\n",
       "      <td>562.2</td>\n",
       "      <td>18.56</td>\n",
       "      <td>4.80</td>\n",
       "      <td>33.28</td>\n",
       "      <td>32.64</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>23.68</td>\n",
       "      <td>8.64</td>\n",
       "      <td>3.292</td>\n",
       "      <td>23.784</td>\n",
       "      <td>10.24</td>\n",
       "      <td>71.68</td>\n",
       "      <td>25.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.546334e+09</td>\n",
       "      <td>549.6</td>\n",
       "      <td>18.24</td>\n",
       "      <td>5.12</td>\n",
       "      <td>33.28</td>\n",
       "      <td>35.20</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.7524</td>\n",
       "      <td>23.68</td>\n",
       "      <td>8.64</td>\n",
       "      <td>3.964</td>\n",
       "      <td>24.944</td>\n",
       "      <td>9.28</td>\n",
       "      <td>72.64</td>\n",
       "      <td>32.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  1004578059  1006706934  1006715799  1006716429  1006727093  \\\n",
       "0  1.546330e+09       558.0       18.56        5.44       33.60       33.28   \n",
       "1  1.546331e+09       552.6       18.56        4.80       33.28       32.64   \n",
       "2  1.546332e+09       549.6       18.24        4.80       33.28       31.36   \n",
       "3  1.546333e+09       562.2       18.56        4.80       33.28       32.64   \n",
       "4  1.546334e+09       549.6       18.24        5.12       33.28       35.20   \n",
       "\n",
       "   1006727361  1008913626  1009074083  1009511425  1009540871  1009984043  \\\n",
       "0        0.96       0.796      0.2376       26.88        8.16       3.244   \n",
       "1        0.64       0.792      0.8652       22.40        8.16       3.988   \n",
       "2        1.28       0.800      0.9020       24.32        9.12       3.124   \n",
       "3        1.28       0.796      0.3804       23.68        8.64       3.292   \n",
       "4        0.96       0.792      0.7524       23.68        8.64       3.964   \n",
       "\n",
       "   1009984060  1010054507  1010086328  1010249061  1010282897  1010397607  \\\n",
       "0      22.348        8.96       76.48        22.8         NaN         NaN   \n",
       "1      21.956        9.92       76.48        31.2         NaN         NaN   \n",
       "2      22.076       10.24       72.32        27.6         NaN         NaN   \n",
       "3      23.784       10.24       71.68        25.2         NaN         NaN   \n",
       "4      24.944        9.28       72.64        32.4         NaN         NaN   \n",
       "\n",
       "   1010409824  \n",
       "0       24.96  \n",
       "1       33.92  \n",
       "2       28.80  \n",
       "3       24.96  \n",
       "4       32.64  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.columns = x2.columns.droplevel(0) #remove amount\n",
    "x2.columns.name = None               #remove categories\n",
    "x2 = x2.reset_index()                #index to columns\n",
    "x2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
