{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7133dd1-a7f1-4dba-8c0e-f16f5d0396fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully read hourly weather and load data (8760 hours)\n",
      "\n",
      "Trying different models...\n",
      "\n",
      "- extra_trees_pipeline\n",
      "- random_forest_pipeline\n",
      "- multi_layer_perceptron\n",
      "- tuned_mlp\n",
      "- tuned_Total_mlp\n",
      "- tuned_Fast_mlp\n",
      "- random_forest\n",
      "- extra_trees\n",
      "- gradient_boosting\n",
      "- todt\n",
      "--- skipped ---\n",
      "- sarimax_with_forecast\n",
      "--- skipped ---\n",
      "\n",
      " n = 4380\n",
      "Computing residuals...\n",
      "... 25%\n",
      "... 50%\n",
      "... 75%\n",
      "Done.\n",
      "\n",
      "The width of the CI = 0.4501\n",
      "The 90.0% confidence interval of the prediction is: [3.3601, 3.8102]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import fcLib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PLOT = False\n",
    "\n",
    "# Import yearly load and outside temperature data from GridWorks\n",
    "df = pd.read_excel(os.getcwd()+'/data/gridworks_yearly_data.xlsx', header=3, index_col = 0)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.index.name = None\n",
    "\n",
    "# Rename columns\n",
    "renamed_columns = {\n",
    "    'Outside Temp F': 'T_OA',\n",
    "    'House Power Required AvgKw': 'Q_load'}\n",
    "df.rename(columns=renamed_columns, inplace=True)\n",
    "\n",
    "# Convert outside air temperature from °F to °C\n",
    "df['T_OA'] = df['T_OA'].apply(lambda x: round(5/9 * (x-32),2))\n",
    "\n",
    "# Keep only date, weather, and load\n",
    "df = df[['T_OA','Q_load']]#[:1000]\n",
    "\n",
    "print(f\"Succesfully read hourly weather and load data ({len(df)} hours)\")\n",
    "\n",
    "# Split the data into X (weather) and y (load)\n",
    "X_columns = ['T_OA']\n",
    "y_columns = ['Q_load']\n",
    "X = df[X_columns]\n",
    "y = df[y_columns]\n",
    "\n",
    "# Create training and testing data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 42)\n",
    "\n",
    "# Create a dict to store prediction values for a 48-hour plot\n",
    "scores = {}\n",
    "data_plots = {}\n",
    "\n",
    "# Iterate through each of the forecaster models\n",
    "print(\"\\nTrying different models...\\n\")\n",
    "library = fcLib.forecasters(fcLib.forecaster_list)\n",
    "\n",
    "for forecaster in library.forecasters:\n",
    "\n",
    "    # Skip forecasters that bug\n",
    "    print(f\"- {forecaster['name']}\")\n",
    "    if forecaster['name'] == 'todt' or forecaster['name'] == 'sarimax_with_forecast': \n",
    "        print(\"--- skipped ---\")\n",
    "        continue\n",
    "\n",
    "    # Fit the model to the training data and predict for the testing data\n",
    "    model = getattr(fcLib, forecaster['fun'])(**forecaster['parameter'])\n",
    "    model.fit(X_train, y_train)\n",
    "    predict = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the rmse and store it in the associated dataframe\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predict))\n",
    "    scores[forecaster['name']] = rmse\n",
    "    #print(f\"- RMSE = {rmse}\\n\")\n",
    "\n",
    "    data_plots[forecaster['name']] = []\n",
    "\n",
    "    # For 48-hour plot\n",
    "    for i in range(48):    \n",
    "        forecast = [[X.T_OA[i].tolist()]]\n",
    "        predict = model.predict(forecast)\n",
    "\n",
    "        if forecaster['name'] == 'gradient_boosting': \n",
    "            data_plots[f\"{forecaster['name']}\"].append(predict[0])\n",
    "        else:\n",
    "            data_plots[f\"{forecaster['name']}\"].append(predict)\n",
    "\n",
    "    if PLOT:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(df.Q_load[0:48].tolist(), label=\"Reality\")\n",
    "        for forecaster in library.forecasters:\n",
    "            if forecaster['name'] == 'todt': continue\n",
    "            if forecaster['name'] == 'sarimax_with_forecast': continue\n",
    "            plt.plot(data_plots[f\"{forecaster['name']}\"], label=f\"Prediction {forecaster['name']}\", alpha=0.6, linestyle='dashed')\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Load\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Now include the confidence intervals using split conformal prediction\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# Seperate the features X (weather) and the variable y (load)\n",
    "X = df[['T_OA']]\n",
    "y = df[['Q_load']]\n",
    "\n",
    "# Split the data into training and holdout sets of same size (8760/2 = 4380)\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, train_size = 0.5, random_state = 42)\n",
    "n = len(X_holdout)\n",
    "print(f\"\\n n = {len(X_holdout)}\")\n",
    "\n",
    "# Train the model with the training set\n",
    "for forecaster in library.forecasters:\n",
    "\n",
    "    # Use random forest\n",
    "    if forecaster['name'] != 'multi_layer_perceptron': continue\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model = getattr(fcLib, forecaster['fun'])(**forecaster['parameter'])\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the holdout data to test the model and get residuals R_1,..., R_n\n",
    "    trues, predicts, residuals = [], [], []\n",
    "    percentage_list = [25, 50, 75]\n",
    "    print(\"Computing residuals...\")\n",
    "    for i in range(len(X_holdout)):\n",
    "        predict = model.predict([[X_holdout.T_OA[i].tolist()]])[0]\n",
    "        true = y_holdout.Q_load.iloc[i]\n",
    "        residual = np.abs(true-predict)\n",
    "        trues.append(true)\n",
    "        predicts.append(predict)\n",
    "        residuals.append(residual)\n",
    "        if int(i/n*100) in percentage_list: \n",
    "            print(f\"... {round(i/n*100)}%\")\n",
    "            percentage_list = percentage_list[1:] if len(percentage_list)>1 else []\n",
    "    print(\"Done.\\n\")\n",
    "\n",
    "    # Sort the residuals\n",
    "    residuals.sort(reverse=False)\n",
    "    \n",
    "    # Get the confidence interval for a new point\n",
    "    new_point = [[5]]\n",
    "    predict = model.predict(new_point)[0]\n",
    "    alpha = 0.1\n",
    "    CI_min = predict - residuals[int((1-alpha)*(n+1))-1]\n",
    "    CI_max = predict + residuals[int((1-alpha)*(n+1))-1]\n",
    "    print(f\"The width of the CI = {round(residuals[int((1-alpha)*(n+1))-1]*2,4)}\")\n",
    "    print(f\"The {round((1-alpha)*100,3)}% confidence interval of the prediction is: [{round(CI_min,4)}, {round(CI_max,4)}]\")\n",
    "\n",
    "# PLOT\n",
    "\n",
    "if PLOT:\n",
    "\n",
    "    plot_length = 50\n",
    "    \n",
    "    plt.figure(figsize=(14,5))\n",
    "    \n",
    "    for delta in [0.1]:\n",
    "    \n",
    "        predicted = []\n",
    "        upper_bounds = []\n",
    "        lower_bounds = []\n",
    "        errors_index = [np.nan]*plot_length\n",
    "        errors_count = 0\n",
    "        \n",
    "        for i in range(plot_length):    \n",
    "            forecast = [[df.T_OA[i].tolist()]]\n",
    "            \n",
    "            predict = model.predict(forecast)[0]\n",
    "            CI_min = predict - residuals[int((1-delta)*(n+1))-1]\n",
    "            CI_max = predict + residuals[int((1-delta)*(n+1))-1]\n",
    "            \n",
    "            predicted.append(predict)\n",
    "            lower_bounds.append(CI_min)\n",
    "            upper_bounds.append(CI_max)\n",
    "    \n",
    "            if df.Q_load.iloc[i] > CI_max or df.Q_load.iloc[i] < CI_min:\n",
    "                errors_index[i] = df.Q_load.iloc[i]\n",
    "                errors_count += 1\n",
    "    \n",
    "        plt.plot(df.Q_load[0:plot_length].tolist(), color='blue', alpha=0.7, label=\"Real load\", linestyle='dashed')  \n",
    "        plt.plot(predicted, color='black', alpha=0.4, label='Predicted load')\n",
    "        plt.fill_between(range(plot_length), lower_bounds, upper_bounds, color='gray', alpha=0.1, label=f'{round((1-delta)*100,1)}% confidence interval')\n",
    "        plt.scatter(range(plot_length), errors_index, marker='o', color='red', label='Real load outside of CI')\n",
    "    \n",
    "    plt.xlabel(\"Time [hours]\")\n",
    "    plt.ylabel(\"Load [kWh]\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"{errors_count} loads ({round(errors_count/plot_length*100,2)}%) are outside of the predicted {round((1-delta)*100,1)}% confidence interval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d95b5024-b618-49ac-8158-90a72c88d82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'extra_trees_pipeline': 0.20654640765743684, 'random_forest_pipeline': 0.19021814249635008, 'multi_layer_perceptron': 0.19612453240225236, 'tuned_mlp': 0.2006555530680047, 'tuned_Total_mlp': 0.19106542722586256, 'tuned_Fast_mlp': 0.19310949631771274, 'random_forest': 0.18983476034813465, 'extra_trees': 0.18983602040183564, 'gradient_boosting': 0.18988618709197216}\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58ca8325-ce03-4705-8cd4-c27cb30e5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n"
     ]
    }
   ],
   "source": [
    "rmse = [value for key, value in scores.items()]\n",
    "forecasters = [key for key, value in scores.items()]\n",
    "print(forecasters[rmse.index(min(rmse))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39266f49-e396-436d-a751-04a4ebbf5930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
